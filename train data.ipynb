{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a3a6d2-ac0e-46a9-ae63-ee21242c487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# STEP 1\n",
    "############# LOADING THE DATASET\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re, nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "\n",
    "test_data_file_name='testing.txt'\n",
    "train_data_file_name='training.txt'\n",
    "test_data_df = pd.read_csv(test_data_file_name, header=None, delimiter=\";\")\n",
    "test_data_df.columns = [\"Text\"]\n",
    "train_data_df = pd.read_csv(train_data_file_name, header=None, delimiter=\";\")\n",
    "\n",
    "train_data_df.columns = [\"Type\",\"Text\"]\n",
    "TypeText=['positive','negative','neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40519831-6624-457f-9607-2597e045709c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>today is the last class of business outcomes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>there is a beautiful weather outside</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type                                          Text\n",
       "0     0  today is the last class of business outcomes\n",
       "1     0          there is a beautiful weather outside"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea7795a-754d-41a9-ab6a-dd6e2a41ecb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have computer and laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't live in Sopot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>winter break is in 4 weeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Text\n",
       "0  i have computer and laptop\n",
       "1       I don't live in Sopot\n",
       "2  winter break is in 4 weeks"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46d1d44-619c-4b15-9e5b-4a866cb44918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d87449-6ea3-4f95-99dc-781bf5f3a34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "0    71\n",
       "1    71\n",
       "2    73\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df['Type'].groupby(train_data_df['Type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a066411-e3a1-4c93-87ea-9d2ce6a87fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zajecia/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zajecia/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "############# STEP 3\n",
    "np.mean([len(s.split(\" \")) for s in train_data_df.Text])\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    # !!! replace the line below with your stopwords list like this\n",
    "    # stop_words=POLISH_STOP_WORDS,\n",
    "    stop_words = 'english',\n",
    "    max_features = 85\n",
    ")\n",
    "\n",
    "corpus_data_features = vectorizer.fit_transform(\n",
    "    train_data_df.Text.tolist() + test_data_df.Text.tolist())\n",
    "corpus_data_features_nd = corpus_data_features.toarray()\n",
    "corpus_data_features_nd.shape\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "dist = np.sum(corpus_data_features_nd, axis=0)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        corpus_data_features_nd[0:len(train_data_df)], \n",
    "        train_data_df.Type,\n",
    "        train_size=0.85, \n",
    "        random_state=1234)\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=X_train, y=y_train)\n",
    "y_pred = log_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c65a523-4447-472c-8822-0e34bd0ce390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad' 'beauti' 'best' 'black' 'brand' 'break' 'busi' 'christma' 'class'\n",
      " 'cold' 'color' 'comput' 'dark' 'day' 'desk' 'don' 'dure' 'earli' 'evalu'\n",
      " 'experi' 'fast' 'fight' 'final' 'finish' 'good' 'grey' 'ha' 'happi'\n",
      " 'hard' 'holiday' 'hp' 'idea' 'iiyama' 'improv' 'insid' 'intel' 'job'\n",
      " 'laptop' 'like' 'lot' 'love' 'm' 'mani' 'monitor' 'month' 'morn' 'new'\n",
      " 'nice' 'onli' 'outcom' 'outsid' 'pc' 'phone' 'plain' 'prefer' 'project'\n",
      " 'realli' 'rest' 'sad' 'school' 'semest' 'ski' 'slow' 'small' 'sopot'\n",
      " 'stand' 't' 'thi' 'thing' 'think' 'time' 'today' 'upcom' 'use' 'veri'\n",
      " 'wa' 'wait' 'wake' 'weather' 'week' 'white' 'winter' 'work' 'year'\n",
      " 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "#what is stemming?\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca7d6ed-3d24-4785-85f6-ac3e1bf25db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the training dataset accuracy...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        12\n",
      "           1       0.71      1.00      0.83        10\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           0.88        33\n",
      "   macro avg       0.90      0.89      0.88        33\n",
      "weighted avg       0.91      0.88      0.88        33\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8,  4,  0],\n",
       "       [ 0, 10,  0],\n",
       "       [ 0,  0, 11]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# STEP 5\n",
    "############# TESTING TRAINING DATASET\n",
    "print(\"Testing the training dataset accuracy...\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf31e73b-faa9-4755-a7be-8a34571266e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral : i have computer and laptop\n",
      "negative : I don't live in Sopot\n",
      "positive : winter break is in 4 weeks\n",
      "The following labels were identified:\n",
      "\n",
      "2: 1\n",
      "1: 1\n",
      "0: 1\n"
     ]
    }
   ],
   "source": [
    "############# STEP 6\n",
    "############# TESTING THE REAL DATASET\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=corpus_data_features_nd[0:len(train_data_df)], y=train_data_df.Type)\n",
    "  \n",
    "test_pred = log_model.predict(corpus_data_features_nd[len(train_data_df):])\n",
    "    \n",
    "import random\n",
    "spl = random.sample(range(len(test_pred)), len(test_pred))\n",
    "purpose=[]\n",
    "for text, type in zip(test_data_df.Text[spl], test_pred[spl]):\n",
    "    print (TypeText[type],':', text)\n",
    "    purpose.append(type)\n",
    "print(\"The following labels were identified:\\n\" )\n",
    "c = Counter(purpose)\n",
    "for letter in c:\n",
    "    print ('%s: %d' % (letter, c[letter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec8aee-81c4-4dae-90cf-37dbf7c26fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
